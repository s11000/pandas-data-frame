{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " G100A007_0610ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6K4tMTjYJC01C3A9gbf3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s11000/pandas-data-frame/blob/main/G100A007_0610ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "qr9BjL0opv1N",
        "outputId": "8674495b-ede8-4607-ed42-0b559fe4d56b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-4a925748c0aa>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    int X[1][2]  = {[1:0]}\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#include <math.h>\n",
        "\n",
        "#define B1  4\n",
        "#define B2  7\n",
        "#define LED 13\n",
        "\n",
        "#define PERCEPTRON  3\n",
        "\n",
        "int X[1][2]  = { {1,0} };\n",
        "\n",
        "/*these matrices was calculated by python */\n",
        "float W1[2][PERCEPTRON] =   {\n",
        "                    {0.38492545, 3.94078829, 4.24865286}, \n",
        "                    {3.83936678, 0.20450267, 4.27767947}\n",
        "                   };\n",
        "float W2[PERCEPTRON][1] =   { {-2.6730679}, \n",
        "                     {-2.3817902}, \n",
        "                    {4.99647104} };\n",
        "float Wo1[1][PERCEPTRON];\n",
        "float sum = 0;\n",
        "float Y = 0;\n",
        "\n",
        "/*sigmoid function*/\n",
        "float sigmoid (float x)\n",
        "{\n",
        "    return 1/(1 + exp(-x));\n",
        "}\n",
        "\n",
        "void setup()\n",
        "{\n",
        "  Serial.begin(115200);\n",
        "\n",
        "  pinMode(B1, INPUT); \n",
        "  pinMode(B2, INPUT); \n",
        "  pinMode(LED, OUTPUT);\n",
        "\n",
        "  digitalWrite(LED, LOW);\n",
        "}\n",
        "\n",
        "void loop()\n",
        "{\n",
        "  X[0][0] = digitalRead(B1);\n",
        "  X[0][1] = digitalRead(B2);\n",
        "  Serial.print(\"Button 1:\"); Serial.print(X[0][0]);\n",
        "  Serial.print(\"\\tButton 2:\"); Serial.println(X[0][1]);\n",
        "\n",
        "  /* calculate forward part based on weights */\n",
        "  //hidden layer\n",
        "  for(int i=0; i<1; i++)\n",
        "  {\n",
        "      for(int j=0;j <PERCEPTRON; j++)\n",
        "      {\n",
        "          for(int k=0; k<2; k++)\n",
        "          {\n",
        "              sum += X[i][k]*W1[k][j];\n",
        "          }\n",
        "          Wo1[i][j] = sigmoid(sum);\n",
        "          sum = 0;  \n",
        "      }\n",
        "  }\n",
        "  //output layer\n",
        "  for(int i=0; i<1; i++)\n",
        "  {\n",
        "      for(int j=0;j <1; j++)\n",
        "      {\n",
        "          for(int k=0; k<PERCEPTRON; k++)\n",
        "          {\n",
        "              Y += Wo1[i][k]*W2[k][j];\n",
        "          } \n",
        "      }\n",
        "  }\n",
        "\n",
        "  Serial.println(Y, 2);\n",
        "\n",
        "  Y = round(Y);\n",
        "  if (int(Y) == 1)\n",
        "    Serial.println(\"---- Should be... ON ----\");\n",
        "  else\n",
        "    Serial.println(\"---- Should be... OFF ----\");\n",
        "  digitalWrite(LED, int(Y));\n",
        "  Y = 0;\n",
        "\n",
        "  delay(2000);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Times to run\n",
        "epoch = 10000\n",
        "\n",
        "\n",
        "# There are 2 inputs\n",
        "inputLayerSize = 2\n",
        "\n",
        "\n",
        "# NN nodes\n",
        "hiddenLayerSize = 3\n",
        "\n",
        "\n",
        "# Only one output\n",
        "outputLayerSize = 1\n",
        "\n",
        "\n",
        "L=0.1\n",
        "\n",
        "\n",
        "# There are 2 inputs for XOR\n",
        "X = np.array( [ [0,0], [0,1], [1,0], [1,1] ] )\n",
        "\n",
        "\n",
        "# The truth table of XOR\n",
        "# ANN just can learn from truly examples!!!\n",
        "#     (adjust the weight and bias to make output is getting close to target by input)\n",
        "Y = np.array( [ [0], [1], [1], [0] ] )\n",
        "\n",
        "\n",
        "def sigmod(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_deriv(x):\n",
        "\treturn x * (1 - x)\n",
        "\t\n",
        "Wh = np.random.uniform(size=(inputLayerSize, hiddenLayerSize))\n",
        "Wz = np.random.uniform(size=(hiddenLayerSize, outputLayerSize))\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "  H = sigmod(np.dot(X, Wh))\n",
        "  Z = np.dot(H, Wz)\n",
        "  E = Y - Z\n",
        "  dZ = E * L\n",
        "  Wz += H.T.dot(dZ)\n",
        "  dH = dZ.dot(Wz.T) * sigmoid_deriv(H)\n",
        "  Wh +=  X.T.dot(dH)\n",
        "\n",
        "\n",
        "print(\"**************** error ****************\") \n",
        "print(E)\n",
        "print(\"***************** output **************\") \n",
        "print(Z)   \n",
        "print(\"*************** weights ***************\") \n",
        "print(\"input to hidden layer weights: \")     \n",
        "print(Wh)\n",
        "print(\"hidden to output layer weights: \")\n",
        "print(Wz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGWB06S3qsiA",
        "outputId": "988f1083-0ca1-4a52-c5a0-d227d044b85a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** error ****************\n",
            "[[-3.77814599e-07]\n",
            " [ 4.56158989e-07]\n",
            " [ 5.04131912e-07]\n",
            " [-6.94601447e-07]]\n",
            "***************** output **************\n",
            "[[3.77814599e-07]\n",
            " [9.99999544e-01]\n",
            " [9.99999496e-01]\n",
            " [6.94601447e-07]]\n",
            "*************** weights ***************\n",
            "input to hidden layer weights: \n",
            "[[ 4.37953108  0.0306285   0.92571624]\n",
            " [ 4.32386247 -1.62363698  0.57830025]]\n",
            "hidden to output layer weights: \n",
            "[[ 4.69344926]\n",
            " [ 1.31331238]\n",
            " [-6.00676088]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Activation, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# 固定亂數種子，使每次執行產生的亂數都一樣\n",
        "np.random.seed(1337)\n",
        "\n",
        "\n",
        "# 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 將 training 的 input 資料轉為3維，並 normalize 把顏色控制在 0 ~ 1 之間\n",
        "X_train = X_train.reshape(-1, 28, 28) / 255.      \n",
        "X_test = X_test.reshape(-1, 28, 28) / 255.\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "# 建立簡單的線性執行的模型\n",
        "model = Sequential()\n",
        "# 加 RNN 隱藏層(hidden layer)\n",
        "model.add(SimpleRNN(\n",
        "    # 如果後端使用tensorflow，batch_input_shape 的 batch_size 需設為 None.\n",
        "    # 否則執行 model.evaluate() 會有錯誤產生.\n",
        "    batch_input_shape=(None, 28, 28), \n",
        "    units= 50,\n",
        "    unroll=True,\n",
        ")) \n",
        "# 加 output 層\n",
        "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "\n",
        "# 一批訓練多少張圖片\n",
        "BATCH_SIZE = 50     \n",
        "BATCH_INDEX = 0     \n",
        "# 訓練模型 4001 次\n",
        "for step in range(1, 4001):\n",
        "    # data shape = (batch_num, steps, inputs/outputs)\n",
        "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :, :]\n",
        "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :]\n",
        "    # 逐批訓練\n",
        "    loss = model.train_on_batch(X_batch, Y_batch)\n",
        "    BATCH_INDEX += BATCH_SIZE\n",
        "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
        "\n",
        "    # 每 500 批，顯示測試的準確率\n",
        "    if step % 500 == 0:\n",
        "        # 模型評估\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], \n",
        "            verbose=False)\n",
        "        print(\"test loss: {}  test accuracy: {}\".format(loss,accuracy))\n",
        "        \n",
        "\n",
        "# 預測(prediction)\n",
        "X = X_test[0:10,:]\n",
        "predictions = model.predict_classes(X)\n",
        "# get prediction result\n",
        "print(predictions)\n",
        "\n",
        "# 模型結構存檔\n",
        "from keras.models import model_from_json\n",
        "json_string = model.to_json()\n",
        "with open(\"SimpleRNN.config\", \"w\") as text_file:\n",
        "    text_file.write(json_string)\n",
        "    \n",
        "# 模型訓練結果存檔\n",
        "model.save_weights(\"SimpleRNN.weight\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "ju2V2TlNqsf6",
        "outputId": "d3c62531-fa77-4079-f054-65a2f225aad3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-18fdaf134bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 固定亂數種子，使每次執行產生的亂數都一樣\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Adam' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mRPO64P-qsc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q9fSXMy_qsaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wsy2x_H3qsWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kluLIVhSqsTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}