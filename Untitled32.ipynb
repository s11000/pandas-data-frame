{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNec9QfEOkM8hPH+b0z+TYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s11000/pandas-data-frame/blob/main/Untitled32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YOF30jx8k_e1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "class CancerNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        model = Sequential()\n",
        "        shape = (height, width, depth)\n",
        "        channelDim = -1\n",
        "\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            shape = (depth, height, width)\n",
        "            channelDim = 1"
      ],
      "metadata": {
        "id": "87mbX99ylDa_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/ASML.csv\")\n",
        "df=train\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "oqk8z6xZlDYR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lZle4xLNlDLy",
        "outputId": "7d1f9460-b61d-463c-8742-825736910418"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "0     2018-01-02  174.139999  177.839996  173.979996  177.729996  168.725327   \n",
              "1     2018-01-03  177.729996  179.580002  177.679993  179.080002  170.006943   \n",
              "2     2018-01-04  180.490005  181.770004  179.399994  180.750000  171.592300   \n",
              "3     2018-01-05  180.839996  183.449997  180.750000  182.869995  173.604919   \n",
              "4     2018-01-08  183.190002  184.460007  182.809998  183.830002  174.516296   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "1254  2022-12-23  546.869995  552.070007  542.530029  551.369995  551.369995   \n",
              "1255  2022-12-27  546.049988  546.500000  536.510010  537.179993  537.179993   \n",
              "1256  2022-12-28  536.700012  541.799988  529.010010  531.640015  531.640015   \n",
              "1257  2022-12-29  541.200012  555.369995  540.150024  551.469971  551.469971   \n",
              "1258  2022-12-30  540.859985  546.479980  536.770020  546.400024  546.400024   \n",
              "\n",
              "       Volume  \n",
              "0      818600  \n",
              "1     1054200  \n",
              "2      915600  \n",
              "3      516100  \n",
              "4      763900  \n",
              "...       ...  \n",
              "1254   602600  \n",
              "1255   802600  \n",
              "1256   609900  \n",
              "1257   841000  \n",
              "1258   701900  \n",
              "\n",
              "[1259 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eeeb0dd-9456-4a69-a735-93fccfee15a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>174.139999</td>\n",
              "      <td>177.839996</td>\n",
              "      <td>173.979996</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>168.725327</td>\n",
              "      <td>818600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>179.580002</td>\n",
              "      <td>177.679993</td>\n",
              "      <td>179.080002</td>\n",
              "      <td>170.006943</td>\n",
              "      <td>1054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>180.490005</td>\n",
              "      <td>181.770004</td>\n",
              "      <td>179.399994</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>171.592300</td>\n",
              "      <td>915600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>180.839996</td>\n",
              "      <td>183.449997</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>182.869995</td>\n",
              "      <td>173.604919</td>\n",
              "      <td>516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>183.190002</td>\n",
              "      <td>184.460007</td>\n",
              "      <td>182.809998</td>\n",
              "      <td>183.830002</td>\n",
              "      <td>174.516296</td>\n",
              "      <td>763900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2022-12-23</td>\n",
              "      <td>546.869995</td>\n",
              "      <td>552.070007</td>\n",
              "      <td>542.530029</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>546.049988</td>\n",
              "      <td>546.500000</td>\n",
              "      <td>536.510010</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>536.700012</td>\n",
              "      <td>541.799988</td>\n",
              "      <td>529.010010</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>541.200012</td>\n",
              "      <td>555.369995</td>\n",
              "      <td>540.150024</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>540.859985</td>\n",
              "      <td>546.479980</td>\n",
              "      <td>536.770020</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>701900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1259 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eeeb0dd-9456-4a69-a735-93fccfee15a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8eeeb0dd-9456-4a69-a735-93fccfee15a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8eeeb0dd-9456-4a69-a735-93fccfee15a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def augFeatures(train):\n",
        "  train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
        "  train[\"year\"] = train[\"Date\"].dt.year\n",
        "  train[\"month\"] = train[\"Date\"].dt.month\n",
        "  train[\"date\"] = train[\"Date\"].dt.day\n",
        "  train[\"day\"] = train[\"Date\"].dt.dayofweek\n",
        "  return train"
      ],
      "metadata": {
        "id": "d3NiKrH6lDJA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "71lpu_XklDBi",
        "outputId": "2089c933-78cf-44f1-ba7d-25011c82d648"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "0     2018-01-02  174.139999  177.839996  173.979996  177.729996  168.725327   \n",
              "1     2018-01-03  177.729996  179.580002  177.679993  179.080002  170.006943   \n",
              "2     2018-01-04  180.490005  181.770004  179.399994  180.750000  171.592300   \n",
              "3     2018-01-05  180.839996  183.449997  180.750000  182.869995  173.604919   \n",
              "4     2018-01-08  183.190002  184.460007  182.809998  183.830002  174.516296   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "1254  2022-12-23  546.869995  552.070007  542.530029  551.369995  551.369995   \n",
              "1255  2022-12-27  546.049988  546.500000  536.510010  537.179993  537.179993   \n",
              "1256  2022-12-28  536.700012  541.799988  529.010010  531.640015  531.640015   \n",
              "1257  2022-12-29  541.200012  555.369995  540.150024  551.469971  551.469971   \n",
              "1258  2022-12-30  540.859985  546.479980  536.770020  546.400024  546.400024   \n",
              "\n",
              "       Volume  \n",
              "0      818600  \n",
              "1     1054200  \n",
              "2      915600  \n",
              "3      516100  \n",
              "4      763900  \n",
              "...       ...  \n",
              "1254   602600  \n",
              "1255   802600  \n",
              "1256   609900  \n",
              "1257   841000  \n",
              "1258   701900  \n",
              "\n",
              "[1259 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc91bda0-df46-4263-97a6-34c16cf91b9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>174.139999</td>\n",
              "      <td>177.839996</td>\n",
              "      <td>173.979996</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>168.725327</td>\n",
              "      <td>818600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>179.580002</td>\n",
              "      <td>177.679993</td>\n",
              "      <td>179.080002</td>\n",
              "      <td>170.006943</td>\n",
              "      <td>1054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>180.490005</td>\n",
              "      <td>181.770004</td>\n",
              "      <td>179.399994</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>171.592300</td>\n",
              "      <td>915600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>180.839996</td>\n",
              "      <td>183.449997</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>182.869995</td>\n",
              "      <td>173.604919</td>\n",
              "      <td>516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>183.190002</td>\n",
              "      <td>184.460007</td>\n",
              "      <td>182.809998</td>\n",
              "      <td>183.830002</td>\n",
              "      <td>174.516296</td>\n",
              "      <td>763900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2022-12-23</td>\n",
              "      <td>546.869995</td>\n",
              "      <td>552.070007</td>\n",
              "      <td>542.530029</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>546.049988</td>\n",
              "      <td>546.500000</td>\n",
              "      <td>536.510010</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>536.700012</td>\n",
              "      <td>541.799988</td>\n",
              "      <td>529.010010</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>541.200012</td>\n",
              "      <td>555.369995</td>\n",
              "      <td>540.150024</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>540.859985</td>\n",
              "      <td>546.479980</td>\n",
              "      <td>536.770020</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>701900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1259 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc91bda0-df46-4263-97a6-34c16cf91b9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc91bda0-df46-4263-97a6-34c16cf91b9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc91bda0-df46-4263-97a6-34c16cf91b9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(train):\n",
        "  train = train.drop([\"Date\"], axis=1)\n",
        "  train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
        "  return train_norm"
      ],
      "metadata": {
        "id": "1rlDIjDWlC-w"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "02YJ8hxApwph",
        "outputId": "44731e22-69be-4b7d-e430-4a1e44f78c3e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "0     2018-01-02  174.139999  177.839996  173.979996  177.729996  168.725327   \n",
              "1     2018-01-03  177.729996  179.580002  177.679993  179.080002  170.006943   \n",
              "2     2018-01-04  180.490005  181.770004  179.399994  180.750000  171.592300   \n",
              "3     2018-01-05  180.839996  183.449997  180.750000  182.869995  173.604919   \n",
              "4     2018-01-08  183.190002  184.460007  182.809998  183.830002  174.516296   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "1254  2022-12-23  546.869995  552.070007  542.530029  551.369995  551.369995   \n",
              "1255  2022-12-27  546.049988  546.500000  536.510010  537.179993  537.179993   \n",
              "1256  2022-12-28  536.700012  541.799988  529.010010  531.640015  531.640015   \n",
              "1257  2022-12-29  541.200012  555.369995  540.150024  551.469971  551.469971   \n",
              "1258  2022-12-30  540.859985  546.479980  536.770020  546.400024  546.400024   \n",
              "\n",
              "       Volume  \n",
              "0      818600  \n",
              "1     1054200  \n",
              "2      915600  \n",
              "3      516100  \n",
              "4      763900  \n",
              "...       ...  \n",
              "1254   602600  \n",
              "1255   802600  \n",
              "1256   609900  \n",
              "1257   841000  \n",
              "1258   701900  \n",
              "\n",
              "[1259 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69f84ec3-bc2e-4179-a62c-d013287d3e88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>174.139999</td>\n",
              "      <td>177.839996</td>\n",
              "      <td>173.979996</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>168.725327</td>\n",
              "      <td>818600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>177.729996</td>\n",
              "      <td>179.580002</td>\n",
              "      <td>177.679993</td>\n",
              "      <td>179.080002</td>\n",
              "      <td>170.006943</td>\n",
              "      <td>1054200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>180.490005</td>\n",
              "      <td>181.770004</td>\n",
              "      <td>179.399994</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>171.592300</td>\n",
              "      <td>915600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>180.839996</td>\n",
              "      <td>183.449997</td>\n",
              "      <td>180.750000</td>\n",
              "      <td>182.869995</td>\n",
              "      <td>173.604919</td>\n",
              "      <td>516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>183.190002</td>\n",
              "      <td>184.460007</td>\n",
              "      <td>182.809998</td>\n",
              "      <td>183.830002</td>\n",
              "      <td>174.516296</td>\n",
              "      <td>763900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2022-12-23</td>\n",
              "      <td>546.869995</td>\n",
              "      <td>552.070007</td>\n",
              "      <td>542.530029</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>551.369995</td>\n",
              "      <td>602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>546.049988</td>\n",
              "      <td>546.500000</td>\n",
              "      <td>536.510010</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>537.179993</td>\n",
              "      <td>802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>536.700012</td>\n",
              "      <td>541.799988</td>\n",
              "      <td>529.010010</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>531.640015</td>\n",
              "      <td>609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>541.200012</td>\n",
              "      <td>555.369995</td>\n",
              "      <td>540.150024</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>551.469971</td>\n",
              "      <td>841000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>540.859985</td>\n",
              "      <td>546.479980</td>\n",
              "      <td>536.770020</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>546.400024</td>\n",
              "      <td>701900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1259 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69f84ec3-bc2e-4179-a62c-d013287d3e88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69f84ec3-bc2e-4179-a62c-d013287d3e88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69f84ec3-bc2e-4179-a62c-d013287d3e88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def buildTrain(train, pastDay=30, futureDay=5):\n",
        "  X_train, Y_train = [], []\n",
        "  for i in range(train.shape[0]-futureDay-pastDay):\n",
        "    X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
        "    Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"Adj Close\"]))\n",
        "  return np.array(X_train), np.array(Y_train)"
      ],
      "metadata": {
        "id": "m2-frlavpwnQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def shuffle(X,Y):\n",
        "  np.random.seed(10)\n",
        "  randomList = np.arange(X.shape[0])\n",
        "  np.random.shuffle(randomList)\n",
        "  return X[randomList], Y[randomList]"
      ],
      "metadata": {
        "id": "HFdtdHmEpwlL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def splitData(X,Y,rate):\n",
        "  X_train = X[int(X.shape[0]*rate):]\n",
        "  Y_train = Y[int(Y.shape[0]*rate):]\n",
        "  X_val = X[:int(X.shape[0]*rate)]\n",
        "  Y_val = Y[:int(Y.shape[0]*rate)]\n",
        "  return X_train, Y_train, X_val, Y_val"
      ],
      "metadata": {
        "id": "22eJNmmVpwi1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read SPY.csv\n",
        "train = pd.read_csv(\"/content/ASML.csv\")\n",
        "\n",
        "# Augment the features (year, month, date, day)\n",
        "train_Aug = augFeatures(train)\n",
        "\n",
        "# Normalization\n",
        "train_norm = normalize(train_Aug)\n",
        "\n",
        "# build Data, use last 30 days to predict next 5 days\n",
        "X_train, Y_train = buildTrain(train_norm, 30, 5)\n",
        "\n",
        "# shuffle the data, and random seed is 10\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "# split training data and validation data\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "# X_trian: (5710, 30, 10)\n",
        "# Y_train: (5710, 5, 1)\n",
        "# X_val: (634, 30, 10)\n",
        "# Y_val: (634, 5, 1)"
      ],
      "metadata": {
        "id": "ksUv6u-cpwgk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def buildOneToOneModel(shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
        "  # output shape: (1, 1)\n",
        "  model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "6nSDzgOhpweW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read SPY.csv\n",
        "train =  pd.read_csv(\"/content/ASML.csv\")\n",
        "\n",
        "# Augment the features (year, month, date, day)\n",
        "train_Aug = augFeatures(train)\n",
        "\n",
        "# Normalization\n",
        "train_norm = normalize(train_Aug)\n",
        "\n",
        "# build Data, use last 30 days to predict next 5 days\n",
        "X_train, Y_train = buildTrain(train_norm, 30, 5)\n",
        "\n",
        "# shuffle the data, and random seed is 10\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "# split training data and validation data\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "# X_trian: (5710, 30, 10)\n",
        "# Y_train: (5710, 5, 1)\n",
        "# X_val: (634, 30, 10)\n",
        "# Y_val: (634, 5, 1)"
      ],
      "metadata": {
        "id": "lWyg7HilrXCp"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def buildOneToOneModel(shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
        "  # output shape: (1, 1)\n",
        "  model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "4TZVdrDYrXAP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = pd.read_csv(\"/content/ASML.csv\")\n",
        "train_Aug = augFeatures(train)\n",
        "train_norm = normalize(train_Aug)\n",
        "# change the last day and next day \n",
        "X_train, Y_train = buildTrain(train_norm, 1, 1)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "\n",
        "# from 2 dimmension to 3 dimension\n",
        "Y_train = Y_train[:,np.newaxis]\n",
        "Y_val = Y_val[:,np.newaxis]\n",
        "\n",
        "model = buildOneToOneModel(X_train.shape)\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_F5m3FFrW9d",
        "outputId": "cca0245a-bdd3-4eb5-bcc0-6c3c4bdd4c7d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 10)             840       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 1, 1)             11        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851\n",
            "Trainable params: 851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "9/9 [==============================] - 5s 198ms/step - loss: 0.0455 - val_loss: 0.0438\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0376 - val_loss: 0.0362\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0304 - val_loss: 0.0290\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0240 - val_loss: 0.0227\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0183 - val_loss: 0.0171\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0125\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0088\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0064 - val_loss: 0.0059\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0038\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 7.5932e-04 - val_loss: 9.6578e-04\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.2028e-04 - val_loss: 8.4234e-04\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 5.5733e-04 - val_loss: 7.7984e-04\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 5.2483e-04 - val_loss: 7.4541e-04\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 5.0588e-04 - val_loss: 7.2418e-04\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 4.9467e-04 - val_loss: 7.0730e-04\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.8436e-04 - val_loss: 6.9363e-04\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7601e-04 - val_loss: 6.8193e-04\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6812e-04 - val_loss: 6.7138e-04\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6151e-04 - val_loss: 6.6267e-04\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5491e-04 - val_loss: 6.5300e-04\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.4950e-04 - val_loss: 6.4457e-04\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.4376e-04 - val_loss: 6.3620e-04\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3875e-04 - val_loss: 6.2945e-04\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3350e-04 - val_loss: 6.2157e-04\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2948e-04 - val_loss: 6.1501e-04\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2415e-04 - val_loss: 6.0771e-04\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.2016e-04 - val_loss: 6.0155e-04\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1579e-04 - val_loss: 5.9539e-04\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1208e-04 - val_loss: 5.8946e-04\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0768e-04 - val_loss: 5.8363e-04\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0359e-04 - val_loss: 5.7792e-04\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0015e-04 - val_loss: 5.7228e-04\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9631e-04 - val_loss: 5.6771e-04\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9249e-04 - val_loss: 5.6240e-04\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8922e-04 - val_loss: 5.5755e-04\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8593e-04 - val_loss: 5.5317e-04\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8250e-04 - val_loss: 5.4880e-04\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.7866e-04 - val_loss: 5.4329e-04\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7561e-04 - val_loss: 5.3807e-04\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7214e-04 - val_loss: 5.3292e-04\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6901e-04 - val_loss: 5.2742e-04\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6572e-04 - val_loss: 5.2413e-04\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6365e-04 - val_loss: 5.1964e-04\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6049e-04 - val_loss: 5.1643e-04\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5684e-04 - val_loss: 5.1050e-04\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5405e-04 - val_loss: 5.0632e-04\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5149e-04 - val_loss: 5.0292e-04\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4848e-04 - val_loss: 4.9863e-04\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4582e-04 - val_loss: 4.9469e-04\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4341e-04 - val_loss: 4.9050e-04\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4223e-04 - val_loss: 4.8660e-04\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3904e-04 - val_loss: 4.8422e-04\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3636e-04 - val_loss: 4.8017e-04\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3501e-04 - val_loss: 4.7691e-04\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3420e-04 - val_loss: 4.7444e-04\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3024e-04 - val_loss: 4.6954e-04\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2660e-04 - val_loss: 4.6579e-04\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2448e-04 - val_loss: 4.6332e-04\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2210e-04 - val_loss: 4.5852e-04\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2038e-04 - val_loss: 4.5575e-04\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1842e-04 - val_loss: 4.5170e-04\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1652e-04 - val_loss: 4.5001e-04\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1421e-04 - val_loss: 4.4731e-04\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1219e-04 - val_loss: 4.4341e-04\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1053e-04 - val_loss: 4.4080e-04\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0873e-04 - val_loss: 4.3800e-04\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0679e-04 - val_loss: 4.3363e-04\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0575e-04 - val_loss: 4.3286e-04\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0372e-04 - val_loss: 4.2967e-04\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0307e-04 - val_loss: 4.2620e-04\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0134e-04 - val_loss: 4.2535e-04\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0219e-04 - val_loss: 4.2141e-04\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9869e-04 - val_loss: 4.2138e-04\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9558e-04 - val_loss: 4.1662e-04\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9459e-04 - val_loss: 4.1393e-04\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9331e-04 - val_loss: 4.1155e-04\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9153e-04 - val_loss: 4.0968e-04\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9105e-04 - val_loss: 4.0681e-04\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9049e-04 - val_loss: 4.0697e-04\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8872e-04 - val_loss: 4.0389e-04\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8600e-04 - val_loss: 4.0221e-04\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8602e-04 - val_loss: 3.9856e-04\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8371e-04 - val_loss: 3.9593e-04\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8298e-04 - val_loss: 3.9463e-04\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8182e-04 - val_loss: 3.9448e-04\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8064e-04 - val_loss: 3.9334e-04\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7998e-04 - val_loss: 3.8993e-04\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7944e-04 - val_loss: 3.8939e-04\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7772e-04 - val_loss: 3.8575e-04\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7665e-04 - val_loss: 3.8450e-04\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7550e-04 - val_loss: 3.8287e-04\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7491e-04 - val_loss: 3.8067e-04\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.7387e-04 - val_loss: 3.8051e-04\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 2.7284e-04 - val_loss: 3.7827e-04\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7226e-04 - val_loss: 3.7644e-04\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7159e-04 - val_loss: 3.7554e-04\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7043e-04 - val_loss: 3.7404e-04\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6973e-04 - val_loss: 3.7210e-04\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6897e-04 - val_loss: 3.7028e-04\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6861e-04 - val_loss: 3.6794e-04\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6764e-04 - val_loss: 3.6650e-04\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6686e-04 - val_loss: 3.6762e-04\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6598e-04 - val_loss: 3.6579e-04\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6535e-04 - val_loss: 3.6534e-04\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6545e-04 - val_loss: 3.6403e-04\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6449e-04 - val_loss: 3.6111e-04\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6357e-04 - val_loss: 3.6061e-04\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6285e-04 - val_loss: 3.6070e-04\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6236e-04 - val_loss: 3.6093e-04\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6183e-04 - val_loss: 3.5828e-04\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6119e-04 - val_loss: 3.5579e-04\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6079e-04 - val_loss: 3.5579e-04\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6016e-04 - val_loss: 3.5574e-04\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5966e-04 - val_loss: 3.5553e-04\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5930e-04 - val_loss: 3.5225e-04\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6193e-04 - val_loss: 3.5414e-04\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6212e-04 - val_loss: 3.5160e-04\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6364e-04 - val_loss: 3.5254e-04\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6021e-04 - val_loss: 3.4940e-04\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5778e-04 - val_loss: 3.5304e-04\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5698e-04 - val_loss: 3.4887e-04\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5622e-04 - val_loss: 3.4751e-04\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5582e-04 - val_loss: 3.4549e-04\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5570e-04 - val_loss: 3.4631e-04\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5665e-04 - val_loss: 3.4436e-04\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5526e-04 - val_loss: 3.4389e-04\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5436e-04 - val_loss: 3.4593e-04\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5489e-04 - val_loss: 3.4249e-04\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5375e-04 - val_loss: 3.4433e-04\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5388e-04 - val_loss: 3.4187e-04\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5311e-04 - val_loss: 3.4194e-04\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5314e-04 - val_loss: 3.4076e-04\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5271e-04 - val_loss: 3.4343e-04\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5203e-04 - val_loss: 3.3895e-04\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5202e-04 - val_loss: 3.3900e-04\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5186e-04 - val_loss: 3.3874e-04\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5170e-04 - val_loss: 3.3982e-04\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5443e-04 - val_loss: 3.3906e-04\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5510e-04 - val_loss: 3.4003e-04\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5594e-04 - val_loss: 3.3602e-04\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5327e-04 - val_loss: 3.3682e-04\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5246e-04 - val_loss: 3.3649e-04\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4929e-04 - val_loss: 3.3719e-04\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4970e-04 - val_loss: 3.3470e-04\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5192e-04 - val_loss: 3.3434e-04\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5644e-04 - val_loss: 3.3526e-04\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5148e-04 - val_loss: 3.3481e-04\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5266e-04 - val_loss: 3.3560e-04\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5026e-04 - val_loss: 3.3337e-04\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5027e-04 - val_loss: 3.3437e-04\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4918e-04 - val_loss: 3.3277e-04\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4795e-04 - val_loss: 3.3277e-04\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4788e-04 - val_loss: 3.3153e-04\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4785e-04 - val_loss: 3.3130e-04\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4754e-04 - val_loss: 3.3205e-04\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4773e-04 - val_loss: 3.3221e-04\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4775e-04 - val_loss: 3.3178e-04\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4877e-04 - val_loss: 3.3215e-04\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4908e-04 - val_loss: 3.2956e-04\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4744e-04 - val_loss: 3.3059e-04\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4669e-04 - val_loss: 3.3036e-04\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4725e-04 - val_loss: 3.3061e-04\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4671e-04 - val_loss: 3.3028e-04\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4671e-04 - val_loss: 3.3046e-04\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4878e-04 - val_loss: 3.2858e-04\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4826e-04 - val_loss: 3.2777e-04\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4623e-04 - val_loss: 3.2841e-04\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4619e-04 - val_loss: 3.2980e-04\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4572e-04 - val_loss: 3.2841e-04\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4601e-04 - val_loss: 3.2867e-04\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4607e-04 - val_loss: 3.2766e-04\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4641e-04 - val_loss: 3.2873e-04\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4743e-04 - val_loss: 3.2923e-04\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4652e-04 - val_loss: 3.2796e-04\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4674e-04 - val_loss: 3.2632e-04\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4714e-04 - val_loss: 3.2844e-04\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4686e-04 - val_loss: 3.2902e-04\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4717e-04 - val_loss: 3.2693e-04\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4538e-04 - val_loss: 3.2579e-04\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4467e-04 - val_loss: 3.2578e-04\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4787e-04 - val_loss: 3.2569e-04\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4667e-04 - val_loss: 3.2586e-04\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4733e-04 - val_loss: 3.2791e-04\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4568e-04 - val_loss: 3.2700e-04\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4551e-04 - val_loss: 3.2605e-04\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4579e-04 - val_loss: 3.2679e-04\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4681e-04 - val_loss: 3.2348e-04\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4474e-04 - val_loss: 3.2698e-04\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4662e-04 - val_loss: 3.2633e-04\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4586e-04 - val_loss: 3.2640e-04\n",
            "Epoch 193: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f608b9b00a0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAdpNrCcrW69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}